# ğŸš¢ **END-to-END Shipments & Compliance Automation Project**

### ğŸ” **Data Cleaning | Power BI Dashboard | SQL DBMS | Docker | Selenium Web Scraping | Python Analytics**

---

## ğŸ“Œ **Project Overview**

This project is a complete **end-to-end data engineering + analytics pipeline**, built using:

* **Excel** for data extraction & sorting
* **Power BI** for dashboard insights
* **MySQL DBMS** for structured storage
* **Python** for cleaning & automation
* **Docker** to containerize the pipeline
* **Selenium** for web scraping
* **Jupyter Notebook** for data analysis

The goal is to take a **raw shipments dataset** and turn it into:
âœ” Clean structured data
âœ” Automated pipelines
âœ” Interactive dashboards
âœ” A reproducible container environment
âœ” A web-scraped structured CSV
âœ” A final cleaned dataset for analysis

This project showcases a **complete real-world workflow** used in:
ğŸ“¦ Logistics,
ğŸ’¼ Compliance,
ğŸ“Š Data Analysis,
ğŸ–¥ Automation, and
â˜ Data Engineering.

---

## ğŸ—‚ **Repository Structure**

```
project-root/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ input.xlsx
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ erd/
â”‚   â””â”€â”€ schema/
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ output/
â”‚   â””â”€â”€ process_data.py
â”‚
â”œâ”€â”€ excel/
â”‚   â”œâ”€â”€ Combined excel worksheets/
â”‚   â””â”€â”€ Snapshots/
â”‚
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ pdf/
â”‚   â””â”€â”€ snapshots/
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ cleaned_population_data.csv
â”‚   â””â”€â”€ data_cleaning_final.ipynb
â”‚
â”œâ”€â”€ selenium/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ scraped_wikipedia_population.csv
â”‚   â””â”€â”€ selenium_scraper.py
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“˜ **1. Excel Processing & Data Cleaning**

**Tasks completed:**

âœ” Removed duplicates
âœ” Cleaned inconsistent fields
âœ” Created 5 computed fields:

* `Clean_Status`
* `EGM_Flag`
* `ROSL_Flag`
* `Gateway_Flag`
* `GST_StateCode`

âœ” Performed **multi-level sorting**
âœ” Combined worksheets
âœ” Prepared final cleaned Excel for Power BI

ğŸ“¸ *Snapshots are stored inside:*
`/excel/Snapshots/`

---

## ğŸ“Š **2. Power BI Dashboard**

Created a complete **Operational Shipments Dashboard**:

âœ” CleanStatus Pie Chart
âœ” GST State Breakdown
âœ” PORT-wise SB Count
âœ” Gateway vs Status Matrix
âœ” Slicer Panel (PORT, IEC, Status, EGM, Gateway)
âœ” Total KPI Cards (SB, IEC, PORT, Gateway, EGM)

ğŸ“ *Dashboard file:*
`/powerbi/dashboards/shipments_dashboard.pbix`

ğŸ“¸ *Screenshots:*
`/powerbi/snapshots/`

ğŸ“„ *PDF export:*
`/powerbi/pdf/`

---

## ğŸ›¢ **3. SQL DBMS (MySQL)**

Created **4 relational tables**:

* `shipment_info`
* `exporter_details`
* `compliance_details`
* `status_details`

âœ” Added foreign keys
âœ” Inserted sample rows
âœ” Wrote analytical SQL queries
âœ” Generated ERD diagram

ğŸ“ *SQL Schema:*
`/database/schema/`

ğŸ“ *ERD Diagram:*
`/database/erd/`

---

## ğŸ³ **4. Docker Containerization**

You built a container that:
âœ” Installs Python dependencies
âœ” Mounts input/output volumes
âœ” Runs `process_data.py`
âœ” Produces `/output/cleaned_shipments.csv`

### **Run Instructions:**

```bash
docker build -t shipments-cleaner .
docker run --rm -v "${PWD}/data:/data" -v "${PWD}/output:/output" shipments-cleaner
```

ğŸ“ Files:

* `docker/Dockerfile`
* `docker/process_data.py`
* `docker/output/cleaned_shipments.csv`

---

## ğŸŒ **5. Selenium Web Scraping**

You automated scraping of **Wikipedia â€“ List of countries by population**.

âœ” Extracted tabular data
âœ” Converted to structured rows/columns
âœ” Saved output CSV
âœ” Captured screenshots

ğŸ“ Files:

* `/selenium/selenium_scraper.py`
* `/selenium/scraped_wikipedia_population.csv`
* `/selenium/screenshots/`

---

## ğŸ **6. Python Data Manipulation**

A complete cleaning script in Jupyter Notebook containing:

âœ” Data type corrections
âœ” Text trimming
âœ” Column transformations
âœ” Grouping, filtering
âœ” Final exported CSV

ğŸ“ Notebook:
`/python/data_cleaning_final.ipynb`

ğŸ“ Output CSV:
`/python/cleaned_population_data.csv`

---

## ğŸ§© **7. Final Deliverables**

Your project contains all required outputs:

### âœ” Excel cleaning

### âœ” Power BI Dashboard

### âœ” SQL DBMS + ERD

### âœ” Docker container

### âœ” Selenium script + CSV

### âœ” Python notebook

### âœ” GitHub repository

### âœ” Professional README.md (this file)

---

## ğŸ§ª **How to Run the Project**

### **1. Clone the Repository**

```bash
git clone https://github.com/<your-username>/shipment-project.git
cd shipment-project
```

### **2. Run Docker Pipeline**

```bash
docker build -t shipments-cleaner .
docker run --rm -v "${PWD}/data:/data" -v "${PWD}/output:/output" shipments-cleaner
```

### **3. Run Selenium Scraper**

```bash
python selenium/selenium_scraper.py
```

### **4. Open Power BI Dashboard**

File: `powerbi/dashboards/shipments_dashboard.pbix`

## â­ **Technologies Used**

| Category      | Tools            |
| ------------- | ---------------- |
| Data Cleaning | Excel, Python    |
| Visualization | Power BI         |
| Database      | MySQL            |
| Automation    | Docker           |
| Web Scraping  | Selenium         |
| Analytics     | Jupyter Notebook |

---
--
